\section{Introduction}

To incentivize the reduction of building energy consumption, the U.S. government
launched the Better Buildings Challenge to make buildings at least 20 percent
more efficient by 2020~\cite{doe2013better}. To achieve this goal, many
organizations are applying data analytics to the thousands of sensing and
control points\footnote{A sensing or control ``point'' is a sensor, a
  controller, or a software value.} in buildings to detect wasteful, incorrect,
and inefficient operation.  Many promising analytical approaches have been
created that demonstrate promise for substantial energy savings~\cite{find}.
However, these analytic engines are \emph{tightly coupled} to the database
schemas and metadata conventions in the buildings for which they were desgined
and cannot easily be applied to different buildings in which the type, location,
and relationships between are represented differently. Unfortunately, most
buildings use different metadata conventions depending on the type of equipment
in the building, the vendors of the equipment, and the contractors who
originally installed it. The process of {\em mapping} a new building to the
inputs of an analytics engine is currently a manual process that often involves
a technician visiting the building to visually inspect the equipment
installation. It can take days or weeks and is a key obstacle to the widespread
use of building analytics.

Several solutions have been proposed to facilitate the mapping problem.
Bhattarcharya et al~\cite{arka} use a programming language based solution,
where they derive a set of regular expressions from a handful of labeled examples
to normalize the sensor point names.
%This approach assumes a consistent format for all point names, which is not the
%case in practice, as shown in Table~\ref{table:ex}.
Schumann et al~\cite{ibm} develop a probabilistic framework to classify sensor types
based on the similarity between a building's point names and entries in a manually constructed dictionary.
%However, the performance of this method is limited by the coverage and
%diversity of entries listed in the dictionary, and the dictionary size becomes
%intractable when there exist a lot of variations of the same type, or
%conflicting definitions of a dictionary entry in different buildings.
Hong et al~\cite{cikm} formulate an active learning based approach to
iteratively acquire human labels for building point names and propagate the
acquired labels among similar points in the same building.  These approaches can
significantly reduce the time required for each new building, but they all still
require some manual mapping, one building at a time.

Additionally, the mapping problem cannot be solved simply by throwing more
person hours at the problem. Even after a building is fully mapped, a new
analytics engine may be developed that requires a different kind of metadata,
e.g. which devices are on the northern side of the building, or which sensors
are affected by a given air handler unit. These and other types of metadata may
never even have been encoded in the original databases at all. Thus, as energy
models and building analytics engines become more nuanced, the mapping problem
will become increasingly important.

In this paper, we envision a technology that would enable any new building
analytics engine to quickly be applied to the 10's of millions of commercial
buildings across the globe. Doing so would enable a new market where boutique
analytics could quickly be matched with the buildings they would benefit the
most. The key to this vision is to perform all mapping operations automatically
and to remove the human from the scalability equation entirely. Any such system
would not need to do perfect mapping; it must only do a first pass that is good
enough to flag the right buildings for a more detailed, manual mapping process.

In this work, we take a first step towards scalable building analytics by
developing new techniques to automatically infer metadata in a building {\em
  without} manual labelling. The insight that guides our solution is that a
sensor typically has two attributes -- its name (a text string) and its
numerical readings generated over time. The names are likely to be good
indicators of metadata structure but are not consistent across buidlings, while
the readings are likely to be poor indicators of metadata but are more
consistent across buildings. Our techniques combine the complementary strengths
of these two attributes to automatically create metadata for one building based
on another building. More specifically, our approach comprises three steps. 1) we start
with a fully labeled building and train multiple classifiers o label new points
based on the data associated with them. These classifiers model the metadata of a
sensor based on the raw data, e.g. air temperature sensors have different values
and change more slowly than light or $CO_2$ sensors. 2) We take a different,
unlabeled building and cluster its points based on their names. The clustering
algorithm tries to group the sensors based on patterns in their names such as
the phrases ``temp'' or ``occ''. 3) We use the classifiers from the first
building to label the points in the second building, weighting them based on how
consistent their labels are with the name clustering. Thus, our approach builds
on and improves upon techniques from {\em transfer learning}~\cite{lwe}: it
learns a model of the metadata from a labeled building and modifies that model
so it can be applied to another, unlabeled building.

To evaluate this approach, we use a dataset with 7 days of data from over 3,000
sensors located in 3 commercial buildings across 2 different college
campuses. Metadata was created manually for all buildings. Then, we applied our
techniques on each building to automatically infer the metadata of the other 2
buildings. The results indicate that this approach can automatically label at
least 36\% of the points with more than 85\% accuracy, and in some cases labels
up to 81\% of the points with 96\% accuracy. In contrast, training classifiers
on one building and applying directly to another building without reweighting
achieves only 63\% label accuracy on average. Our technique does not label all
points, but those that are labeled have high label accuracy. Thus, it will only
support a fraction of analytics algorithms, depending on which sensors they
process. Before concluding, we present two techniques that are showing promise
to improve this coverage and expand support for a larger fraction of analytics
algorithms.

