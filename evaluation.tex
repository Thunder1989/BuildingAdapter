\section{Evaluation}
To demonstrate the effectiveness and usefulness of our methodology, we evaluate our technique in two different scenarios: a) intra building, that is, the 
training and testing data for classification is taken from the same building, and b) inter building, where the training and testing instances are from two 
distinct buildings respectively. We also analyze how the amount of training instances and the window size of segment affect the performance of classification. We also discuss how each feature variable contributes to the classification thus helping determine when to use certain set of features. At last, we show a small application as a case study built based on the generated type information in two buildings, which would be difficult to achieve in the absence of sensor type metadata.

\subsection{Taxonamy}
In this paper, we consider 6 types of sensors, which are $CO_{2}$, humidity, room temperature, setpoint, air flow volume, other temperature. Specifically, room 
temperature includes only sensors that measure the air temperature of rooms and other temperatures covers all other temperature measurements such as supply 
air/return air/mixed air temperature and supply/return water temperature. We also put only one general type for setpoint which includes all types of setpoints 
installed in the buildings.

\subsection{Experimental Setup}
The data we used is collected in one week from two separate buildings on two campuses. One is from the Rice Hall at 
the University of Virginia, where the sensors report to a database~\cite{trane} from every 10 seconds to every 10 minutes. The other building is the Sutardja Dai Hall (SDH) at UC Berkeley where the deployed 
sensors~\cite{keti, bacnet} report to an archiver~\cite{smap} periodically from every 5 seconds to every 10 minutes. The number of each type of sensors in 
each buidlings is given in Table~\ref{table:spec} and the type ground truth for each sensor stream is expanded based on the metadata in the database.

\begin{table}[ht!]
\caption{Number of Sensors by Type}
\centering % used for centering table
\begin{tabular}{c c c}% centered columns (4 columns)
\hline %inserts single horizontal lines
Type & Rice & SDH \\ % inserts table 
\hline\hline % inserts double horizontal line
$CO_{2}$ & 1 & 2 \\ % inserting body of the table
humidity & 2 & 4 \\
room temp. & 3 & 2 \\
setpoint & 4 & 7 \\
air volume & 5 & 5 \\ 
other temp. & 6 & 5 \\ \hline
\end{tabular}
\label{table:spec} % is used to refer this table in the text
\end{table}

All our learning and classification processes are implemented based on the scikit-learn~\cite{scikit} library, which is an open-source machine learning package implemented mostly in python and provides all the APIs in python.

\subsection{Baseline and Metrics}
As a baseline to compare our proposed approach against, we adpot a simple feature extraction scheme for each trace $F=\{med, var\}$, where $med$ and $var$ is just the $median$ and $variance$ computed over the entire trace.

For classification, we measure the averaged cross-validation accuracy in two different scenarios (intra- and inter- buildings). In the intra-building case, the 
data from a single building is split into training and testing sets, where the results illustrate how accurate the type information can be inferred using local 
information. The inter-building experiment performs training and testing across buildings, i.e, train the classifier on the data from building A and test it 
on building B, and this set of experiments shows how much we can infer the type information of one building based on the knowledge from some other building.

For identifying potential misclassifications, we choose the true-positive rate (TPR, also known as recall), false-positive rate (FPR, also known as fall-out) and positive predictive 
value (PPV, also known as precision) as metrics to evaluate the performance of our entropy-based aprroach when making different choice of threshold. In our 
case, a true-positive (TP) is when an instance considered to be misclassified is actually a correct classification while a false-positive (FP) is when an instance 
considered to be misclassfied is misclassified.

\subsection{Classification Accuracy}
We run the two types of experiments described above, i.e, the intra- and inter- building tests, to examine the effectiveness of feature design and measure how well 
the classifier performs. We also experiment with different amount of training instances to examine how that affects the classification accuracy, which also gives 
some insight on how many instances are needed to bootstrap the classification process. The classfication results are summarized in Table~\ref{table:rice},~\ref{table:sdh},~\ref{table:rice_x},~\ref{table:sdh_x}.

\subsubsection{Intra Building Performance}
From the last column in Table~\ref{table:rice} and~\ref{table:sdh}, we see that type classification in a single building achieves accuracy of 91\% and 92\% on SDH and Rice Hall respectively, for leave-one-out (LOO) cross validation\footnote{In LOO cross validation, each learning set takes all the instances except one with the test set being the sample held out.}. The only type we have difficulty differentiating is ``other temp'', which contains temperature measurements for air and water in the HVAC ventilation system, and particularly, the return air temperature measurements are almost identical to the ones mearsuring air temperature in rooms because what the return duct exhausts is mostly the air in a room.

\begin{table*}[ht!]
\caption{Intra-building Classification Accuracy for Rice Hall}
\centering % used for centering table
\begin{tabular}{c | c | c | c | c | c | c}% centered columns (4 columns)
\hline %inserts single horizontal lines
Type & 5\% & 10\% & 20\% & 33\% & 50\% & LOO\\ % inserts table 
%heading
\hline\hline % inserts double horizontal line
$CO_{2}$ & 51.3 (38.5) & 83.7 (26.5) & 98.4 (3.1) & 100.0 (0) & 93.8 (6.25) & 93.8\\ \hline
Humidity & 59.6 (26.5) & 66.8 (23.4) & 80.8 (9.3) & 82.3 (0.3) & 87.5 (4.2) & 83.3\\ \hline
Room temp & 89.0 (9.3) & 93.0 (3.0) & 95.6 (1.9) & 93.3 (0.3) & 97.2 (0) & 95.1\\ \hline
Setpoint & 97.0 (2.4) & 97.5 (2.2) & 99.2 (0.6) & 99.2 (0.3) & 98.5 (0.7) & 99.2\\ \hline
Air volume & 22.2 (28.1) & 35.5 (21.9) & 46.7 (22.7) & 79.2 (5.9) & 41.7 (8.3) & 83.3\\ \hline
Other temp & 54.7 (8.8) & 64.8 (5.1) & 70.0 (1.9) & 72.7 (6.9) & 74.7 (1.9) & 74.8\\ \hline
Overall & 80.4 (3.0) & 85.9 (2.1) & 90.0 (0.6) & 90.9 (0.9) & 91.4 (0.3) & 91.7\\ \hline
\end{tabular}
\label{table:rice} % is used to refer this table in the text
\end{table*}

\begin{table*}[ht!]
\caption{Intra-building Classification Accuracy for SDH}
\centering % used for centering table
\begin{tabular}{c | c | c | c | c | c | c}% centered columns (4 columns)
\hline %inserts single horizontal lines
Type & 5\% & 10\% & 20\% & 33\% & 50\% & LOO\\ % inserts table 
%heading
\hline\hline % inserts double horizontal line
$CO_{2}$ & 80.4 (15.7) & 87.8 (8.8) & 91.4 (7.2) & 89.5 (4.8) & 92.3 (0) & 96.2\\ \hline
Humidity & 91.6 (10.8) & 94.4 (7.7) & 97.6 (1.5) & 98.1 (1.4) & 100.0 (0) & 98.1\\ \hline
Room temp & 98.3 (3.3) & 98.9 (1.5) & 99.2 (0.6) & 98.4 (0.7) & 97.7 (1.4) & 99.1\\ \hline
Setpoint & 99.2 (1.0) & 99.6 (0.2) & 99.5 (0.4) & 99.7 (0.1) & 99.5 (0.2) & 99.5\\ \hline
Air volume & 78.4 (10.0) & 87.1 (5.8) & 92.7 (4.9) & 96.8 (1.6) & 98.7 (0) & 97.5\\ \hline
Other temp & 23.7 (15.0) & 38.4 (11.0) & 62.3 (11.1) & 68.9 (3.5) & 75.7 (2.0) & 73.0\\ \hline
Overall & 93.4 (1.3) & 95.6 (0.9) & 97.2 (0.8) & 97.8 (0.2) & 98.2 (0.3) & 98.3\\ \hline
\end{tabular}
\label{table:sdh} % is used to refer this table in the text
\end{table*}

\subsubsection{Inter Building Performance}
This set of experiments illustrates how accurately we can refer the type information of one building based on the knowledge from another building. The overall accuracy for the two buildings by training on the entire data set (train on SDH for Rice and train on Rice for SDH) is around 82\%, as seen from the last columns in Table~\ref{table:rice_x} and~\ref{table:sdh_x}.

\begin{table*}[ht!]
\caption{Inter-building Classification Accuracy for Rice Hall}
\centering % used for centering table
\begin{tabular}{c | c | c | c | c | c | c}% centered columns (4 columns)
\hline %inserts single horizontal lines
Type & 5\% & 10\% & 20\% & 33\% & 50\% & 100\% \\ % inserts table 
%heading
\hline\hline % inserts double horizontal line
$CO_{2}$ & 29.7 (17.9) & 45.6 (22.7) & 75.0 (16.3) & 93.8 (5.1) & 93.8 (6.3) & 87.5\\ \hline
Humidity & 50.9 (18.8) & 72.1 (14.5) & 76.2 (9.6) & 76.4 (6.4) & 89.6 (2.1) & 87.5\\ \hline
Room temp & 97.6 (6.7) & 99.4 (1.5) & 100.0 (0) & 97.2 (3.5) & 100.0 (0) & 100.0\\ \hline
Setpoint & 97.8 (1.8) & 98.2 (1.4) & 98.0 (1.2) & 97.7 (0.3) & 97.5 (0.5) & 98.9\\ \hline
Air volume & 57.5 (16.8) & 58.3 (17.5) & 66.7 (7.5) & 63.9 (10.4) & 70.8 (12.5) & 83.3\\ \hline
Other temp & 5.3 (4.9) & 10.8 (6.2) & 11.1 (4.3) & 16.8 (4.1) & 18.9 (5.5) & 19.3\\ \hline
Overall & 73.1 (2.1) & 76.9 (2.3) & 78.3 (2.0) & 79.1 (0.2) & 81.3 (0.7) & 81.9\\ \hline
\end{tabular}
\label{table:rice_x} % is used to refer this table in the text
\end{table*}

\begin{table*}[ht!]
\caption{Inter-building Classification Accuracy for SDH}
\centering % used for centering table
\begin{tabular}{c | c | c | c | c | c | c} \hline
Type & 5\% & 10\% & 20\% & 33\% & 50\% & 100\%\\ % inserts table 
\hline\hline % inserts double horizontal line
$CO_{2}$ & 63.5 (39.5) & 96.9 (4.7) & 90.8 (16.5) & 93.6 (4.8) & 92.3 (1.9) & 98.1\\ \hline
Humidity & 67.4 (35.4) & 86.3 (27.8) & 98.1 (2.1) & 96.2 (2.7) & 98.1 (1.9) & 98.1\\ \hline
Room temp & 78.0 (18.5) & 78.2 (11.3) & 72.9 (3.3) & 77.9 (3.4) & 80.3 (3.5) & 53.2\\ \hline
Setpoint & 77.4 (17.1) & 83.3 (8.6) & 86.5 (8.7) & 87.9 (5.5) & 87.2 (3.5) & 91.8\\ \hline
Air volume & 13.8 (18.7) & 15.2 (11.8) & 37.8 (11.1) & 42.4 (12.3) & 50.3 (2.7) & 71.5\\ \hline
Other temp & 48.3 (10.3) & 49.7 (5.4) & 58.4 (9.0) & 45.0 (6.4) & 45.9 (5.4) & 67.6\\ \hline
Overall & 68.2 (10.9) & 74.1 (5.3) & 78.4 (5.0) & 80.3 (2.1) & 81.2 (5.9) & 83.0\\ \hline
\end{tabular}
\label{table:sdh_x} % is used to refer this table in the text
\end{table*}

\subsubsection{Learning Bootstrapping}
In Table~\ref{table:sdh},~\ref{table:rice},~\ref{table:sdh_x},~\ref{table:rice_x}, the last columns demonstrate how accurately we can do classification on average. There also remains the question of how many number of instances we need to bootstrap the learning process for both of the intra- and inter- building cases. To examine the impact of number of instances on classification accuracy, we use different percentage of the original data set as training set, i.e, 5\%, 10\%, 20\%, 33\%,
50\%, and the results are presented as the first five columns in each table. For each percentage of training process, we apply stratified sampling\footnote{The sampled set contains the same percentage of samples of each class as the original complete set.} on the original set and repeat the same percentage 1/percentage times to get an averaged accuracy for that percentage. The standard deviation is also shown (in bracket) for each perentage. We can clearly see a trend that more
training instances yield better classification results in all cases. However, we can also notice that after having 20\% of the complete set (which is $\sim$120 instances and $\sim$260 instances for Rice and SDH respectively) the accuracy doesn't increase too much even reaching 50\% of the complete set. This indicates that we don't need too many instances to bootstrap the learning process within or across buildings to accomplish sensor type classification tasks.

\subsection{Window Length Sensitivity}
Remember that all the above classification results were obtained using features extracted in 45-minute long window on the original sensor traces. To corroborate our decision, we study how different size of time window affects the classification and Figure~\ref{fig:window} shows the results. For intra-building case, the classification is not sensitive to different window size as can be seen in the figure: basically, accuracy stays almost the same for both buildings because within the same building, as long as we can capture the short term characteristics in windowed time slots for sensor dynamics, the granularity of the time window size doesn't make much difference. However, for inter-building case, the time window size matters in the way that the local micro-climate in one building can be quite different from another, we need to ``tune'' this common short term window to capature the dynamics that can be used to infer type information across buildings. Therefore, even though we achieve decent type classification accuracy across buildings, (i.e, use information from one building to help classify the traces in another building), we still need to optimize the size of time window, which is 45 minutes in our case. We believe this ``tuning'' is significant to such kind of learning across buildings and is straightforward to achieve in general.

\begin{figure}[h!]
\centering
	\includegraphics[width=0.45\textwidth]{./fig/window.eps}
\caption{Classification accuracy for intra- and inter- building testing with different size of window. Intra- case performs LOO cross validation while inter- case runs 10-fold cross validation.}
\label{fig:window}
\end{figure}

\subsection{Feature Importance and Selection}


\subsection{Identifying Potential Misclassification}
As we discussed in early section, being able to identify misclassified instances in sensor type classification is vital to improving the overall accuracy. To identify potential misclassified instances, we propose to quantify the ``uncertainty'' of classification with the entropy-based approach described in Section 3.3. Figure~\ref{fig:cdf} shows the CDF of class probability entropy of classification in the intra- and inter- building scenarios. We see that the collection of correct
classification (solid lines) has a distinct distribution from the collection of misclassfication (dotted lines). Based on such distinction in the distribution, we can choose a certain entropy value as threshold and filter out all the classified instances whose class probablity entropy is greater than the threshold outputted by the forest. Figure~\ref{fig:roc} illustrates the performance of our entropy-based approach to identifying potential misclassification. Here are the definitions needed to understand the statistics:

$S_{1}$: the set of instance whose class probablity entropy is greater than the threshold.

$S_{2}$: the set of instance falling in $S_{1}$ that is misclassified in the classfication process.

$S_{3}$: the set of instance falling in $S_{1}$ that is correctly classified in the classfication process.

$S_{4}$: the set of instance that is misclassified in the classfication process.

$S_{5}$: the set of instance that is correctly classified in the classfication process.

And, 
\begin{displaymath}
TPR = \frac{|S_{2}|}{|S_{4}|},\quad
FPR = \frac{|S_{3}|}{|S_{5}|},\quad
PPV = \frac{|S_{2}|}{|S_{1}|},\quad
\end{displaymath}
Where $|\cdot|$ is the cardinality of a set. We see that as the threshold value increases, both the TPR (recall) and FPR (fall-out) decrease while the PPV (precision) keeps increasing. In our case, a smaller threshold essentially leads to more instances being filtered out as potential misclassification ``candidates'' thus helping identify more acutal misclassified instances. However, the more candidates we filter our, the more instances we need to manually inspect,
which inevitably leads to lower precision of the identificatoin process. So we want to strike a balance between achieving a high recall rate as well as maintaining a high precision. As a result, we suggest picking a threshold somewhere between 0.4 and 0.45 is appropriate. In intra-building case, such a threshold (0.4~0.45) helps identify $\sim$30\% of the misclassified instances for Rice and $\sim$50\% for SDH while resulting in that $\sim$70\% and $\sim$50\% of the instances
needing manual inspection are correct classification, for Rice and SDH respectively. As for the inter-building case, our approach is able to identify $\sim$75\% of the misclassified instances for both Rice and SDH with an overhead of $\sim$40\% and $\sim$70\% in the inspection candidates, for Rice and SDH respectively.

\begin{figure*}[ht!]
\centering
	\begin{subfigure}{0.48\textwidth}
                \centering
		\includegraphics[width=\textwidth]{./fig/cdf_intra.eps}
                \caption{Intra-building Classification}
                \label{fig:cdf_intra}
	\end{subfigure}
	\begin{subfigure}{0.48\textwidth}
                \centering
		\includegraphics[width=\textwidth]{./fig/cdf_inter.eps}
                \caption{Inter-building Classification}
                \label{fig:cdf_inter}
	\end{subfigure}
\caption{The CDF curves depict the class probability entropy distribution for the both collection of correct and wrong classification in the intra- and inter- building test cases.}
\label{fig:cdf}
\end{figure*}

\begin{figure*}[ht!]
\centering
	\begin{subfigure}{0.48\textwidth}
                \centering
		\includegraphics[width=\textwidth]{./fig/roc_intra.eps}
                \caption{Intra-building Performance}
                \label{fig:roc_intra}
	\end{subfigure}
	\begin{subfigure}{0.48\textwidth}
                \centering
		\includegraphics[width=\textwidth]{./fig/roc_inter.eps}
                \caption{Inter-building Performance}
                \label{fig:roc_inter}
	\end{subfigure}
\caption{The ROC curves depict the sensitivity of misclassification identification to different entropy threshold value. Choosing a threshold somewhere between 0.4 and 0.45 achieves the best compromise between recall and precision. }
\label{fig:roc}
\end{figure*}

\subsection{Case Study}
TBD
