\section{Evaluation}
To demonstrate the effectiveness and usefulness of our methodology, we evaluate our technique in two different scenarios: a) intra building, that is, the 
training and testing data for classification is taken from the same building, and b) inter building, where the training and testing instances are from two 
distinct buildings respectively. We also analyze how the amount of training instances and the window size of segment affect the performance of classification. We also discuss how each feature variable contributes to the classification thus helping determine when to use certain set of features. At last, we show a small application as a case study built based on the generated type information in two buildings, which would be difficult to achieve in the absence of sensor type metadata.

\subsection{Taxonamy}
In this paper, we consider 6 types of sensors, which are $CO_{2}$, humidity, room temperature, setpoint, air flow volume, other temperature. Specifically, room 
temperature includes only sensors that measure the air temperature of rooms and other temperatures covers all other temperature measurements such as supply 
air/return air/mixed air temperature and supply/return water temperature. We also put only one general type for setpoint which includes all types of setpoints 
installed in the buildings.

\subsection{Experimental Setup}
The data we used are collected in one week from two separate buildings on two campuses. One is from the Rice Hall at 
the University of Virginia, where the sensors report to a central database~\cite{trane} from every 10 seconds to every 10 minutes. The other building is the Sutardja Dai Hall (SDH) at UC Berkeley where the deployed 
sensors~\cite{keti, bacnet} report to an archiver~\cite{smap} periodically from every 5 seconds to every 10 minutes.The number of each type of sensors in 
each buidlings is given in table~\ref{table:spec} and the type ground truth for each sensor stream is expanded based on the metadata in the database.

\begin{table}[ht!]
\caption{Number of Sensors by Type}
\centering % used for centering table
\begin{tabular}{c c c}% centered columns (4 columns)
\hline %inserts single horizontal lines
Type & Rice & SDH \\ % inserts table 
\hline\hline % inserts double horizontal line
$CO_{2}$ & 1 & 2 \\ % inserting body of the table
humidity & 2 & 4 \\
room temp. & 3 & 2 \\
setpoint & 4 & 7 \\
air volume & 5 & 5 \\ 
other temp. & 6 & 5 \\ \hline
\end{tabular}
\label{table:spec} % is used to refer this table in the text
\end{table}

All our learning and classification processes are implemented based on the scikit-learn~\cite{scikit} library, which is an open-source machine learning package implemented mostly in python and provides all the APIs in python.

\subsection{Baseline and Metrics}
As a baseline to compare our proposed approach against, we adpot a simple feature extraction scheme for each trace $F=\{med, var\}$, where $med$ and $var$ is just the $median$ and $variance$ computed over the entire trace.

For classification, we measure the averaged cross-validation accuracy in two different scenarios (intra- and inter- buildings). In the intra-building case, the 
data from a single building is split into training and testing sets, where the results illustrate how accurate the type information can be inferred using local 
information. The inter-building experiment performs training and testing across buildings, i.e, train the classifier on the data from building A and test it 
on building B, and this set of experiments shows how much we can infer the type information of one building based on the knowledge from some other building.

For identifying potential misclassifications, we choose the true-positive rate (TPR, also known as recall rate), false-positive rate (FPR) and positive predictive 
value (PPV, also known as precision) as metrics to evaluate the performance of our entropy-based aprroach when making different choices of thresholding. In our 
case, a true-positive (TP) is when an instance considered to be misclassified is actually a correct classification while a false-positive (FP) is when an instance 
considered to be misclassfied is misclassified.

\subsection{Classification Accuracy}
We run the two types of experiments described above, i.e, the intra- and inter- building tests, to examine the effectiveness of feature design and measure how well 
the classifier performs. We also experiment with different amount of training instances to examine how that affects the classification accuracy, which also gives 
some insight on how many instances are needed to bootstrap the classification process. The classfication results are summarized in Table~\ref{table:sdh},~\ref{table:rice},~\ref{table:sdh_x},~\ref{table:rice_x}.

\subsubsection{Intra Building Performance}
From the last column in Table~\ref{table:sdh} and~\ref{table:rice}, we see that type classification in a single building achieves accuracy of 91\% and 92\% on SDH and Rice Hall respectively, for leave-one-out (LOO) cross validation\footnote{In LOO cross validation, each learning set takes all the instances except one with the test set being the sample held out.}. The only type we have difficulty differentiating is ``other temp'', which contains temperature measurements for air and water in the HVAC ventilation system, and particularly, the return air temperature measurements are almost identical to the ones mearsuring air temperature in rooms because what the return duct exhausts is mostly the air in a room.

\begin{table*}[ht!]
\caption{Intra-building Classification Accuracy for Rice Hall}
\centering % used for centering table
\begin{tabular}{c | c | c | c | c | c | c}% centered columns (4 columns)
\hline %inserts single horizontal lines
Type & 5\% & 10\% & 20\% & 33\% & 50\% & LOO\\ % inserts table 
%heading
\hline\hline % inserts double horizontal line
$CO_{2}$ & 51.3 (38.5) & 83.7 (26.5) & 98.4 (3.1) & 100.0 (0) & 93.8 (6.25) & 93.8\\ \hline
Humidity & 51.9.6 (26.5) & 66.8 (23.4) & 80.8 (9.3) & 82.3 (0.3) & 87.5 (4.2) & 83.3\\ \hline
Room temp & 89.0 (9.3) & 93.0 (3.0) & 95.6 (1.9) & 93.3 (0.3) & 97.2 (0) & 95.1\\ \hline
Setpoint & 97.0 (2.4) & 97.5 (2.2) & 99.2 (0.6) & 99.2 (0.3) & 98.5 (0.7) & 99.2\\ \hline
Air volume & 22.2 (28.1) & 35.5 (21.9) & 46.7 (22.7) & 79.2 (5.9) & 41.7 (8.3) & 83.3\\ \hline
Other temp & 54.7 (8.8) & 64.8 (5.1) & 70.0 (1.9) & 72.7 (6.9) & 74.7 (1.9) & 74.8\\ \hline
Overall & 80.4 (3.0) & 85.9 (2.1) & 90.0 (0.6) & 90.9 (0.9) & 91.4 (0.3) & 91.7\\ \hline
\end{tabular}
\label{table:rice} % is used to refer this table in the text
\end{table*}

\begin{table*}[ht!]
\caption{Intra-building Classification Accuracy for SDH}
\centering % used for centering table
\begin{tabular}{c | c | c | c | c | c | c}% centered columns (4 columns)
\hline %inserts single horizontal lines
Type & 5\% & 10\% & 20\% & 33\% & 50\% & LOO\\ % inserts table 
%heading
\hline\hline % inserts double horizontal line
$CO_{2}$ & 80.4 (15.7) & 87.8 (8.8) & 91.4 (7.2) & 89.5 (4.8) & 92.3 (0) & 96.2\\ \hline
Humidity & 91.6 (10.8) & 94.4 (7.7) & 97.6 (1.5) & 98.1 (1.4) & 100.0 (0) & 98.1\\ \hline
Room temp & 98.3 (3.3) & 98.9 (1.5) & 99.2 (0.6) & 98.4 (0.7) & 97.7 (1.4) & 99.1\\ \hline
Setpoint & 99.2 (1.0) & 99.6 (0.2) & 99.5 (0.4) & 99.7 (0.1) & 99.5 (0.2) & 99.5\\ \hline
Air volume & 78.4 (10.0) & 87.1 (5.8) & 92.7 (4.9) & 96.8 (1.6) & 98.7 (0) & 97.5\\ \hline
Other temp & 23.7 (15.0) & 38.4 (11.0) & 62.3 (11.1) & 68.9 (3.5) & 75.7 (2.0) & 73.0\\ \hline
Overall & 93.4 (1.3) & 95.6 (0.9) & 97.2 (0.8) & 97.8 (0.2) & 98.2 (0.3) & 98.3\\ \hline
\end{tabular}
\label{table:sdh} % is used to refer this table in the text
\end{table*}

\subsubsection{Inter Building Performance}
This set of experiments illustrate how accurately we can refer the type information of one building based on the knowledge from another building. The 

\begin{table*}[ht!]
\caption{Inter-building Classification Accuracy for Rice Hall}
\centering % used for centering table
\begin{tabular}{c | c | c | c | c | c}% centered columns (4 columns)
\hline %inserts single horizontal lines
Type & 5\% & 10\% & 20\% & 33\% & 50\% \\ % inserts table 
%heading
\hline\hline % inserts double horizontal line
$CO_{2}$ & 29.7 (17.9) & 45.6 (22.7) & 75.0 (16.3) & 93.8 (5.1) & 93.8 (6.3)\\ \hline
Humidity & 50.9 (18.8) & 72.1 (14.5) & 76.2 (9.6) & 76.4 (6.4) & 89.6 (2.1)\\ \hline
Room temp & 97.6 (6.7) & 99.4 (1.5) & 100.0 (0) & 97.2 (3.5) & 100.0 (0)\\ \hline
Setpoint & 97.8 (1.8) & 98.2 (1.4) & 98.0 (1.2) & 97.7 (0.3) & 97.5 (0.5)\\ \hline
Air volume & 57.5 (16.8) & 58.3 (17.5) & 66.7 (7.5) & 63.9 (10.4) & 70.8 (12.5)\\ \hline
Other temp & 5.3 (4.9) & 10.8 (6.2) & 11.1 (4.3) & 16.8 (4.1) & 18.9 (5.5)\\ \hline
Overall & 73.1 (2.1) & 76.9 (2.3) & 78.3 (2.0) & 79.1 (0.2) & 81.3 (0.7)\\ \hline
\end{tabular}
\label{table:rice_x} % is used to refer this table in the text
\end{table*}

\begin{table*}[ht!]
\caption{Inter-building Classification Accuracy for SDH}
\centering % used for centering table
\begin{tabular}{c | c | c | c | c | c} \hline
Type & 5\% & 10\% & 20\% & 33\% & 50\% \\ % inserts table 
\hline\hline % inserts double horizontal line
$CO_{2}$ & 63.5 (39.5) & 96.9 (4.7) & 90.8 (16.5) & 93.6 (4.8) & 92.3 (1.9)\\ \hline
Humidity & 67.4 (35.4) & 86.3 (27.8) & 98.1 (2.1) & 96.2 (2.7) & 98.1 (1.9)\\ \hline
Room temp & 78.0 (18.5) & 78.2 (11.3) & 72.9 (3.3) & 77.9 (3.4) & 80.3 (3.5)\\ \hline
Setpoint & 77.4 (17.1) & 83.3 (8.6) & 86.5 (8.7) & 87.9 (5.5) & 87.2 (3.5)\\ \hline
Air volume & 13.8 (18.7) & 15.2 (11.8) & 37.8 (11.1) & 42.4 (12.3) & 50.3 (2.7)\\ \hline
Other temp & 48.3 (10.3) & 49.7 (5.4) & 58.4 (9.0) & 45.0 (6.4) & 45.9 (5.4)\\ \hline
Overall & 68.2 (10.9) & 74.1 (5.3) & 78.4 (5.0) & 80.3 (2.1) & 81.2 (5.9)\\ \hline
\end{tabular}
\label{table:sdh_x} % is used to refer this table in the text
\end{table*}

\subsubsection{Training Bootstrapping}

\subsection{Window Length Sensitivity}
Remember that all the above classification results were obtained using features extracted in 45-minute long window on the original sensor traces. To corroborate our decision, we study how different size of time window affects the classification and Figure~\ref{fig:window} shows the results. For intra-building case, the classification is not sensitive to different window size 

\begin{figure}[h!]
\centering
	\includegraphics[width=0.45\textwidth]{./fig/window.eps}
\caption{Classification accuracy for intra- and inter- building testing with different size of window. Intra- case performs LOO cross validation while inter- case runs 10-fold cross validation.}
\label{fig:window}
\end{figure}


\subsection{Feature Importance and Selection}

\subsection{Identifying Misclassification}
\begin{figure*}[ht]
\centering
	\begin{subfigure}{0.48\textwidth}
                \centering
		\includegraphics[width=\textwidth]{./fig/cdf_intra.eps}
                \caption{Intra-building Classification}
                \label{fig:cdf_intra}
	\end{subfigure}
	\begin{subfigure}{0.48\textwidth}
                \centering
		\includegraphics[width=\textwidth]{./fig/cdf_inter.eps}
                \caption{Inter-building Classification}
                \label{fig:cdf_inter}
	\end{subfigure}
\caption{The CDF curves depict the class probability entropy distribution for collection of both correct and wrong classification in intra- and inter- building test cases.}
\label{fig:cdf}
\end{figure*}

\begin{figure*}[ht]
\centering
	\begin{subfigure}{0.48\textwidth}
                \centering
		\includegraphics[width=\textwidth]{./fig/roc_intra.eps}
                \caption{Intra-building Performance}
                \label{fig:cdf_intra}
	\end{subfigure}
	\begin{subfigure}{0.48\textwidth}
                \centering
		\includegraphics[width=\textwidth]{./fig/roc_inter.eps}
                \caption{Inter-building Performance}
                \label{fig:cdf_inter}
	\end{subfigure}
\caption{The ROC curves depict the sensitivity of the raw signal and mid-frequency IMFs to the threshold value. We choose the 0.2 FPR point as the boundary threshold for each room. }
\label{fig:cdf}
\end{figure*}

\subsection{Case Study}
