\section{Evaluation}
To demonstrate the effectiveness of our method, we evaluate our transfer learning based classification technique on actual data and point names of sensors from three commercial buildings. Extensive experiments demonstrate that our technique is able to accurately classify by type for a considerable portion of examples without human intervention. We also discuss how the threshold parameter $\delta$ on similarity score affect the learning accuracy and also explain the decision of how to set such a parameter.

\subsection{Taxonomy and Data Collection}
\begin{figure}[t]
\centering
\includegraphics[width=0.38\textwidth]{./fig/hvac}
\caption{A typical HVAC system consisting of an air handler unit (AHU), several variable air volume boxes (VAV), water-based heating/cooling pipes and air circulation ducts. (Figure used with permission from the authors of~\cite{sentinel}.)}
\label{fig:hvac}
\end{figure}

Figure~\ref{fig:hvac} illustrates a typical heating, ventilation, and air conditioning (HVAC) system deployed in modern commercial buildings. 
An HVAC system usually uses a combination of hot and cold water pipes in conjunction with
air handler units (AHU) to maintain the appropriate thermal environment within the building.
An HAVC system usually consists of several AHUs and each AHU is responsible for a physical zone
in the building. An AHU consists of variable speed drives that supply cold air
(cooled by the supplied cold water) using ducts to VAV boxes distributed throughout the building.
The hot water loop is also connected to these VAV boxes using separate pipes. Each VAV box
controls the amount of air to be let into an HVAC zone using dampers, whose opening angle
can be programmed. A reheat coil, which uses supplied hot water, is used to heat the air to
meet the appropriate HVAC settings for each zone.

Table~\ref{table:num} summarizes all the types of sensors evaluated in our analysis in these three buildings and the number of sensors of each type. ``Room temperature'' measures the temperature in room and for a better understanding, all the other temperature measurements on water circulation and air ventilation are illustrated in Figure~\ref{fig:hvac}. For setpoints, we assign only
one general type which includes all set points for every actuator configured in the building.

Our evaluation data set containing both data and point names of sensor streams is collected from over 2,500 sensors of different types deployed in three commercial buildings. 
We collected a week's worth of data from each building.
Specifically, Building A is the Rice Hall at the University of Virginia, where the sense points report to a database by Trane anywhere between every 10 seconds to every 10 minutes.
Both building B and C are from UC Berkeley: B is the Sutardja Dai Hall with sensors and equippment from KETI\footnote{\url{http://www.keti.re.kr/}}  and Siemens, while building C is the Soda Hall that uses an archaic system by Barrington Controls which is no longer in business. 
Points and sensors in these two buildings transmit data to an archiver~\cite{smap} periodically from anywhere between every 5 seconds to every 10 minutes.


\begin{table}[t]
\centering
\begin{tabular}{l | l l l}
\hline
& \multicolumn{3}{c}{Building} \\
Type & A & B & C\\
\hline\hline
$CO_{2}$ & 16 & 52 & 0\\
Humidity & 54 & 52 & 0\\
Air Pressure & 142 & 216 & 215\\
Room Temp & 159 & 231 & 208\\
Facility Operation Status & 59 & 72 & 41\\
Facility Control & 0 & 138 & 403\\
Setpoint & 140 & 486 & 229\\
Air Flow Volume & 14 & 172 & 9\\
Damper Position & 0 & 290 & 10\\
Fan Speed & 0 & 25 & 15\\
HW Supply Temp & 27 & 1 & 0\\
HW Return Temp & 15 & 1 & 0\\
CW Supply Temp & 18 & 2 & 11\\
CW Return Temp & 15 & 3 & 10\\
Supply Air Temp & 20 & 17 & 3\\
Return Air Temp & 6 & 2 & 4\\
Mixed Air Temp & 5 & 2 & 3\\
Ice Tank Entering Temp & 1 & 2 & 0\\
Ice Tank Leaving Temp & 1 & 4 & 0\\
Occupancy & 25 & 52 & 0\\
Timer & 0 & 0 & 15\\ \hline
Sum & 575 & 1124 & 1166\\ \hline
\end{tabular}
\caption{Number of points by type for the 3 test buildings. ``Temp" stands for ``temperature", ``HW" for ``hot water" and ``CW" for ``cold water".}
\label{table:num}
\end{table}


All of our learning and classification processes are implemented based on the scikit-learn~\cite{scikit} library, which is an open-source machine learning package 
implemented mostly in Python providing a rich set of APIs.

\subsection{Base Classifiers and Baseline}
\label{sec:baseline}
Our transfer learning based approach exploits a few base classifiers. Each base classifier will be trained on the same set of data features from the source building in a general way, therefore there is no particular requirement on what classifiers should be selected here.
Particularly, we employ three base classifiers: ranfom forest, linear regression and support vector machines with RBF kernels.


\begin{figure*}[ht!]
\centering
  \begin{subfigure}{0.32\textwidth}
                \centering
    \includegraphics[width=\textwidth]{./fig/TL_AB.eps}
                \caption{A and B}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
                \centering
    \includegraphics[width=\textwidth]{./fig/TL_BC.eps}
                \caption{B and C}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
                \centering
    \includegraphics[width=\textwidth]{./fig/TL_AC.eps}
                \caption{A and C}
  \end{subfigure}
\caption{Type classification accuracy (Acc) against labeled percentage (Cov) with transfer learning between different pairs of buildings (denoted as X->Y). As we increse the threshold, the coverage drops while the overall accuracy increases. }
\label{fig:tl_acc}
\end{figure*}


\begin{table*}[]
\centering
\begin{tabular}{r|c|c|c}
\hline
 & A     & B     & C     \\ \hline
A & N/A   & 0.754/0.496/0.510 & 0.921/0.766/0.538 \\ \hline
B & 0.614/0.228/0.362 & N/A   & 0.513/0.247/0.258 \\ \hline
C & 0.582/0.299/0.421 & 0.393/0.158/0.190 & N/A   \\ \hline
\end{tabular}
\caption{Base classifier performance across buildings on data features. The three numbers are the accuracy for random forest, logistic regression and SVM respectively.}
\label{acc_base}
\end{table*}

\begin{table*}[]
\centering
\begin{tabular}{r|c|c|c|c|c|c}
\hline
\multirow{2}{*}{} & \multicolumn{2}{c|}{A} & \multicolumn{2}{c|}{B} & \multicolumn{2}{c}{C} \\ \cline{2-7} 
                  & Acc        & F1        & Acc        & F1        & Acc        & F1        \\ \hline
A                 & N/A      & N/A     & 0.943/0.934      & 0.936/0.931     & 0.977/0.970      & 0.981/0.971     \\ \hline
B                 & 0.897/0.875     & 0.932/0.913     & N/A      & N/A     & 0.950/0.952      & 0.939/0.937     \\ \hline
C                 & 0.862/0.862     & 0.864/0.864     & 0.726/0.702      & 0.691/0.726     & N/A     & N/A     \\ \hline
\end{tabular}
\caption{Accuracy and F1 score of transfer learning and the best baseline with $\delta$=0.4. Each cell contains two numbers for our approach and the baseline respectively. Overall, our approach outperforms the baseline.}
\label{table:f1}
\end{table*}


There is an intrinsic tradeoff between the prediction accuracy and the percentage can be labeled, since we set a threshold on the average weight of base classifiers. 
As a baseline to compare our proposed approach against, we take the subset of examples in the new building that get labeled by the transfer learning process, and apply the base classifiers to predict labels on the same subset. 

\subsection{Base Classifier Performance}
We first examine the performance of the base classifiers we choose when applied across buildings. 
There are three pair of choices and for each pair the training/testing can be conducted either way, therefore, we have six testing case. The classification results is illustrated in Figure~\ref{fig:tl_acc}.
As shown in Table~\ref{acc_base}, the base classifiers achieve the accuracy anywhere between 0.158 and 0.921.


\subsection{Transfer Learning Performance}
We investigate the overall accuracy of transfer learning for type classification across our three testing buildings, and the results are illustrated in Figure~\ref{fig:tl_acc}.

On such imbalanced data sets, investigation of accuracy only is not enough. We also measure the weighted macro F1 score of classification for our approach and the baseline. The weighted macro F1 score is an altered version of macro F1 score~\cite{yang}, which calculates the F1 score for each class, where ``one-versus-all'' binary classification is performed, and weight the resulting F1 of each class by support (the number of true instances for each label). The results are shown in Table~\ref{table:f1}. 

%Paired two sample t-test is performed to validate the statistical significance of improvement from our method over the best-performing baseline. 

\subsection{Number of Clusters}
Although we appeal to a non-parametric Bayesion clustering method in our algorithm to generate clusters on the testing building, we further justify such a choice by demonstrating how sensitive the transfer learning can be to the number of clusters generated.

%\begin{figure}[t]
%\centering
%\includegraphics[width=0.42\textwidth]{./fig/TL_AB.eps}
%\caption{The effect of number of clusters on transfer learning performance.}
%\label{fig:num}
%\end{figure}
%\subsection{Exploitation of Labels in the New Building}

\subsection{Discussion}
\paragraph{Unlabeled Streams}
With a threshold on the average weight of base classifiers, our transfer learning based technique is able to label only a portion of the streams in the new building, which leaves many unlabeled.
The coverage might be increased by finding the nearest neighbors in a certain radius of those unlabeled and combine them.

\paragraph{Complementing Traditional Labeling}
Our method is designed to complement the traditional labeling techniques, rather then replacing them.
With a consierable percentage automatically labeled by our technique as a first step, the labeling process of a new building is expected to be accelerated significantly.

\paragraph{Better Features for Classifiers} The performance of transfer learning and classification processes in our work is bounded by the base classifiers which rely only on a set of general features. The line of work to represent time series with discretized symbols (e.g., the SAX~\cite{sax}) or primitive ``shapes'' (e.g., the ``shapelets''~\cite{shapelet1, shapelet2}) doesn't work well for our problem due to the variability in ``shapes'' and unpredictable human noises. Therefore, we wish to explore how using external or domain-specific knowledge could help improve the classification accuracy. 

\paragraph{Multiple Buildings as Source}
In our study, only one building is exploited as the source to transfer knowledge. In practice, it is common to have labels for multiple buildings available and combining them all as the source to transfer knowledge would  achieve better performance.