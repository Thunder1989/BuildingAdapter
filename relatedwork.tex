\section{Related Work}
To the best of our knowledge, we are the first to develop transfer learning based solutions to address the problem of sensor type classification across buildings.

Researchers have tried to systematically address the problem of point name normalization.
Dawson-Haggerty et al.~\cite{boss} and Krioukov et al.~\cite{bas}
introduce a Building Operating System Service stack, whereby
the underlying building sensor stock is presented to applications through a driver-based model \
and an application stack provides a fuzzy-query based interface to the namespace exposed
through the driver interface.
Although this architecture has useful properties for easing generalizability across
buildings, the driver registration process is still done manually.
Bhattarcharya et al~\cite{arka} exploit a programming language based solution,
where they derive a set of regular expressions from a handful of labeled examples
to normalize the point name of sensors.
This approach assumes a consistent format for all point names across buildings, which is not the case in practice, as shown in Table~\ref{table:ex}.
Schumann et al~\cite{ibm} develop a probabilistic framework to classify sensor types
based on the similarity of a raw point name to the entries in a manually constructed dictionary.
However, the performance of this method is limited by the coverage and diversity of entries listed in the dictionary, and the dictionary size becomes intractable when there exist a lot of variations of the same type, or conflicting definitions of a dictionary entry in different buildings.
Hong et al~\cite{cikm} formulate an active learning based approach to iteratively
acquire human labels for the building and propogate pseudo labels among points.
However, all of those existing work depend on manual annotations, and thus none of them address the scalability issue of metadata
normalization across buildings nor leverages the knowledge from already labeled buildings.

Transfer learning saves extra effort in manual annotation by exploiting the labels in the already well annotated buildings.
There are several categories of tranfer learning as comprehensively surveyed in~\cite{transfer1}.
% We only briefly summarizes the differences.
Inductive transfer learning~\cite{transfer2} assumes the set of class labels in the target domain is different from the source domain, and aims at achieving high performance in the target domain by transferring knowledge from the source domain \cite{multitask} has a similar setting, but tries to learn from the target and source domains simultaneously.
Transductive transfer learning~\cite{transfer3} assumes the source and target domains have the same set of labels, but different marginal distribution of features (i.e., $p(x)$) or conditional distribution of labels (i.e., $p(y|x)$). This breaks down the basic identical and independent assumption in classical supervised learning techniques and makes them inept. Typical solutions in transductive transfer learning is to reweight the classifiers' predictions in target domain. Instance-based local weighting~\cite{weight1,weight2,weight3} has been well studied, but these work assumed that the training and testing distributions differ only in $p(x)$ but not in $p(y|x)$. Ensemble methods are also explored to assign the weights \cite{ensem1,ensem2} in transductive transfer learning. However, these local weights are decided only based on the training data.
Our problem setting falls into this category. In particular, we assume we have well-labeled instances in one building, i.e., the source domain, but do not have any labeled instances in the target building, i.e., the target domain.
% Such knowledge transfer is possible when the training domain and the test domain have the same set of class labels.


%Timeseries Representation~\cite{sax,shapelet1,shapelet2}

% The use of transfer learning is motivated by the fact that people often have one or a few buildings labeled of which they want to take advantage to aid the labeling of a new buidling.
% Transfer learning is a useful technique in the building space because the effort it takes to label sensors in a single building is high.
% We want to leverage the knowledge gained in one building to quickly label another with minimal effort.
% One category of transfer learning uses well-labeled data from one domain\footnote{A ``domain'' particularly refers to a data set in this paper.}
% to classify examples in a new, related domain.
% Classical supervised learning techniques are not useful for transferring knowledge across domains in this setting because
% The reason that traditional supervised learning techniques is not successful in transferring knowledge across domains in our case is because
% it requires the training and testing examples to be sampled i.i.d. from the same distribution. This basic requirement does not hold here.
